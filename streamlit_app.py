"""
AADHAAR ENROLMENT DATA DASHBOARD
Interactive Streamlit Dashboard for Comprehensive Enrollment Analysis
"""

import streamlit as st
import pandas as pd
import numpy as np
import os
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# Page configuration
st.set_page_config(
    page_title="Aadhaar Enrolment Analytics",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
    <style>
    .metric-card {
        background-color: #f0f2f6;
        padding: 20px;
        border-radius: 10px;
        margin: 10px 0;
    }
    .header-text {
        color: #1f77b4;
        font-weight: bold;
    }
    </style>
""", unsafe_allow_html=True)

@st.cache_data
def load_data():
    """Load and consolidate data from all three CSV files"""
    csv_folder = r"c:\Users\RUTURAJ\D_Drive\Desktop\Coding\AAdhar hackathon\api_data_aadhar_enrolment"
    csv_files = [
        "api_data_aadhar_enrolment_0_500000.csv",
        "api_data_aadhar_enrolment_500000_1000000.csv",
        "api_data_aadhar_enrolment_1000000_1006029.csv"
    ]
    
    dataframes = []
    for file in csv_files:
        filepath = os.path.join(csv_folder, file)
        df = pd.read_csv(filepath)
        dataframes.append(df)
    
    df_full = pd.concat(dataframes, ignore_index=True)
    df_full['date'] = pd.to_datetime(df_full['date'], format='%d-%m-%Y')
    df_full['total_enrolment'] = df_full['age_0_5'] + df_full['age_5_17'] + df_full['age_18_greater']
    df_full['year'] = df_full['date'].dt.year
    df_full['month'] = df_full['date'].dt.month
    df_full['day_of_week'] = df_full['date'].dt.day_name()
    
    return df_full

# Load data
df_full = load_data()

# Sidebar navigation
st.sidebar.title("üìä Navigation")
page = st.sidebar.radio(
    "Select Analysis Section",
    [
        "Overview",
        "Time-Based Patterns",
        "Geographic Dominance",
        "Age Group Analysis",
        "Data Quality",
        "Infrastructure Analysis",
        "Key Insights"
    ]
)

# ========================================================================================
# PAGE 1: OVERVIEW
# ========================================================================================
if page == "Overview":
    st.title("üìä Aadhaar Enrolment Analysis Dashboard")
    st.markdown("---")
    
    # Key metrics
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            "üìà Total Records",
            f"{len(df_full):,}",
            "1M+ records"
        )
    
    with col2:
        st.metric(
            "üóìÔ∏è Date Range",
            f"{df_full['date'].min().strftime('%b %d')} - {df_full['date'].max().strftime('%b %d')}",
            "2025"
        )
    
    with col3:
        st.metric(
            "üåç States",
            f"{df_full['state'].nunique()}",
            "Covered"
        )
    
    with col4:
        st.metric(
            "üèôÔ∏è Districts",
            f"{df_full['district'].nunique()}",
            "Unique"
        )
    
    st.markdown("---")
    
    # Summary statistics
    col1, col2, col3 = st.columns(3)
    
    with col1:
        total_enrolment = df_full['total_enrolment'].sum()
        st.metric("üë• Total Enrolments", f"{total_enrolment:,}")
    
    with col2:
        avg_daily = df_full.groupby('date')['total_enrolment'].sum().mean()
        st.metric("üìÖ Avg Daily Enrolment", f"{avg_daily:,.0f}")
    
    with col3:
        pincodes = df_full['pincode'].nunique()
        st.metric("üìÆ Unique Pincodes", f"{pincodes:,}")
    
    st.markdown("---")
    
    # Data sample
    st.subheader("üìã Data Sample")
    st.dataframe(df_full.head(10), width='stretch')
    
    # Overall statistics
    st.subheader("üìä Overall Statistics")
    col1, col2 = st.columns(2)
    
    with col1:
        st.info("""
        **Dataset Characteristics:**
        - Time Period: March - December 2025
        - Geographic Coverage: 55 states/UTs, 985 districts
        - Age Groups: 0-5, 5-17, 18+
        - All records have complete data (no missing values)
        """)
    
    with col2:
        stats_df = pd.DataFrame({
            'Metric': ['Min Daily', 'Max Daily', 'Mean Daily', 'Median Daily'],
            'Enrolments': [
                f"{df_full.groupby('date')['total_enrolment'].sum().min():,}",
                f"{df_full.groupby('date')['total_enrolment'].sum().max():,}",
                f"{df_full.groupby('date')['total_enrolment'].sum().mean():,.0f}",
                f"{df_full.groupby('date')['total_enrolment'].sum().median():,.0f}"
            ]
        })
        st.table(stats_df)

# ========================================================================================
# PAGE 2: TIME-BASED PATTERNS
# ========================================================================================
elif page == "Time-Based Patterns":
    st.title("‚è∞ Time-Based Patterns Analysis")
    st.markdown("_Enrollment behavior reflects policy decisions, not organic user activity_")
    st.markdown("---")
    
    # Daily enrollment trend
    st.subheader("üìà Daily Enrollment Trend")
    daily_enrolments = df_full.groupby('date')['total_enrolment'].sum().reset_index()
    
    fig_daily = px.area(
        daily_enrolments,
        x='date',
        y='total_enrolment',
        title='Daily Enrollment Over Time',
        labels={'date': 'Date', 'total_enrolment': 'Enrolments'},
        template='plotly_white'
    )
    fig_daily.update_traces(fillcolor='rgba(31, 119, 180, 0.3)')
    st.plotly_chart(fig_daily, use_container_width=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.info("""
        **Top 5 Spike Days:**
        Policy-driven campaigns identified
        """)
        top_days = daily_enrolments.nlargest(5, 'total_enrolment')
        for idx, row in top_days.iterrows():
            st.write(f"‚Ä¢ **{row['date'].strftime('%Y-%m-%d')}**: {row['total_enrolment']:,} enrolments")
    
    with col2:
        # Day of week analysis
        dow_analysis = df_full.groupby('day_of_week')['total_enrolment'].sum().reindex(
            ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
        )
        
        st.info("""
        **Day of Week Pattern:**
        Weekdays vs Weekends
        """)
        weekday_avg = dow_analysis[['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']].mean()
        weekend_avg = (dow_analysis['Saturday'] + dow_analysis['Sunday']) / 2
        uplift = ((weekday_avg / weekend_avg - 1) * 100)
        st.write(f"**Weekday activity: {uplift:.1f}% higher than weekends**")
        st.write(f"‚Ä¢ Weekday avg: {weekday_avg:,.0f}")
        st.write(f"‚Ä¢ Weekend avg: {weekend_avg:,.0f}")
    
    st.markdown("---")
    
    # Day of week bar chart
    st.subheader("üóìÔ∏è Enrollment by Day of Week")
    fig_dow = px.bar(
        x=dow_analysis.index,
        y=dow_analysis.values,
        title='Total Enrollment by Day of Week',
        labels={'x': 'Day of Week', 'y': 'Total Enrolments'},
        template='plotly_white',
        color=dow_analysis.values,
        color_continuous_scale='Blues'
    )
    st.plotly_chart(fig_dow, use_container_width=True)
    
    # Monthly trend
    st.subheader("üìÖ Monthly Enrollment Trend")
    monthly_enrolments = df_full.groupby(df_full['date'].dt.to_period('M'))['total_enrolment'].sum()
    monthly_df = pd.DataFrame({
        'Month': [str(x) for x in monthly_enrolments.index],
        'Enrolments': monthly_enrolments.values
    })
    
    fig_monthly = px.bar(
        monthly_df,
        x='Month',
        y='Enrolments',
        title='Monthly Enrollment Distribution',
        template='plotly_white',
        color='Enrolments',
        color_continuous_scale='Viridis'
    )
    st.plotly_chart(fig_monthly, use_container_width=True)

# ========================================================================================
# PAGE 3: GEOGRAPHIC DOMINANCE
# ========================================================================================
elif page == "Geographic Dominance":
    st.title("üó∫Ô∏è Geographic Dominance Analysis")
    st.markdown("_Enrollment is highly concentrated in few regions_")
    st.markdown("---")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        # State concentration - Pareto
        state_totals = df_full.groupby('state')['total_enrolment'].sum().sort_values(ascending=False)
        cumsum = state_totals.cumsum()
        cumsum_pct = (cumsum / cumsum.iloc[-1] * 100)
        states_80pct = (cumsum_pct[cumsum_pct <= 80].shape[0])
        total_states = state_totals.shape[0]
        
        st.metric(
            "üî¥ Pareto Principle",
            f"{states_80pct}/{total_states} states",
            f"Generate 80% of enrolments"
        )
    
    with col2:
        top_10_pct = int(len(df_full.groupby('district')['total_enrolment'].sum()) * 0.1)
        district_contribution = df_full.groupby('district')['total_enrolment'].sum().nlargest(top_10_pct).sum()
        total_enrollment = df_full['total_enrolment'].sum()
        pct_contribution = (district_contribution / total_enrollment * 100)
        
        st.metric(
            "üèôÔ∏è District Concentration",
            f"{pct_contribution:.1f}%",
            f"From top 10% of districts"
        )
    
    st.markdown("---")
    
    # Top states
    st.subheader("ü•á Top 15 States by Enrollment")
    state_summary = df_full.groupby('state').agg({
        'total_enrolment': ['sum', 'count', 'mean'],
        'district': 'nunique'
    }).round(0)
    state_summary.columns = ['Total', 'Records', 'Avg', 'Districts']
    state_summary = state_summary.sort_values('Total', ascending=False).head(15)
    
    fig_states = px.bar(
        state_summary.reset_index(),
        x='state',
        y='Total',
        title='Top 15 States by Enrollment',
        labels={'state': 'State', 'Total': 'Total Enrolments'},
        template='plotly_white',
        color='Total',
        color_continuous_scale='Blues'
    )
    fig_states.update_xaxes(tickangle=-45)
    st.plotly_chart(fig_states, use_container_width=True)
    
    st.dataframe(state_summary, width='stretch')
    
    st.markdown("---")
    
    # Top districts
    st.subheader("üèôÔ∏è Top 15 Districts by Enrollment")
    district_summary = df_full.groupby('district')['total_enrolment'].sum().nlargest(15)
    
    fig_districts = px.bar(
        x=district_summary.values,
        y=district_summary.index,
        orientation='h',
        title='Top 15 Districts by Enrollment',
        labels={'x': 'Total Enrolments', 'y': 'District'},
        template='plotly_white',
        color=district_summary.values,
        color_continuous_scale='Greens'
    )
    st.plotly_chart(fig_districts, use_container_width=True)

# ========================================================================================
# PAGE 4: AGE GROUP ANALYSIS
# ========================================================================================
elif page == "Age Group Analysis":
    st.title("üë∂ Age Group Clustering Analysis")
    st.markdown("_Enrollment patterns reflect administrative priorities, not demographics_")
    st.markdown("---")
    
    # Age group totals
    age_0_5_total = df_full['age_0_5'].sum()
    age_5_17_total = df_full['age_5_17'].sum()
    age_18_greater_total = df_full['age_18_greater'].sum()
    total_all = age_0_5_total + age_5_17_total + age_18_greater_total
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric(
            "üë∂ Ages 0-5",
            f"{age_0_5_total:,}",
            f"{age_0_5_total/total_all*100:.1f}% - Child drives"
        )
    
    with col2:
        st.metric(
            "üéì Ages 5-17",
            f"{age_5_17_total:,}",
            f"{age_5_17_total/total_all*100:.1f}% - School-based"
        )
    
    with col3:
        st.metric(
            "üë® Ages 18+",
            f"{age_18_greater_total:,}",
            f"{age_18_greater_total/total_all*100:.1f}% - Documents"
        )
    
    st.markdown("---")
    
    # Age distribution pie chart
    col1, col2 = st.columns([1, 1])
    
    with col1:
        age_data = pd.DataFrame({
            'Age Group': ['0-5 years', '5-17 years', '18+ years'],
            'Enrolments': [age_0_5_total, age_5_17_total, age_18_greater_total]
        })
        
        fig_pie = px.pie(
            age_data,
            values='Enrolments',
            names='Age Group',
            title='Age Group Distribution (Overall)',
            template='plotly_white',
            color_discrete_sequence=['#FF6B6B', '#4ECDC4', '#45B7D1']
        )
        st.plotly_chart(fig_pie, use_container_width=True)
    
    with col2:
        st.info("""
        **Administrative Targeting Pattern:**
        
        ‚Ä¢ **65.3%** in 0-5 age group
        - Government child enrolment drives
        - High focus on coverage
        
        ‚Ä¢ **31.6%** in 5-17 age group
        - School-based enrollment initiatives
        - Secondary priority
        
        ‚Ä¢ **3.1%** in 18+ age group
        - Documents/ID requirements
        - Minimal focus
        """)
    
    st.markdown("---")
    
    # Age distribution by top states
    st.subheader("üìä Age Group Distribution by Top 10 States")
    top_states = df_full.groupby('state')['total_enrolment'].sum().nlargest(10).index
    age_by_state = df_full[df_full['state'].isin(top_states)].groupby('state')[
        ['age_0_5', 'age_5_17', 'age_18_greater']
    ].sum()
    
    fig_age_state = px.bar(
        age_by_state.reset_index().melt(id_vars='state', var_name='Age Group', value_name='Enrolments'),
        x='state',
        y='Enrolments',
        color='Age Group',
        title='Age Group Distribution by Top 10 States',
        template='plotly_white',
        barmode='stack'
    )
    fig_age_state.update_xaxes(tickangle=-45)
    st.plotly_chart(fig_age_state, use_container_width=True)
    
    # Anomalies
    st.subheader("‚ö†Ô∏è Age Group Anomalies")
    age_anomalies = df_full[(df_full['age_0_5'] > 500) | (df_full['age_18_greater'] > 500)]
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.write(f"**Records with unusual age_0_5 concentration (>500):** {len(age_anomalies[age_anomalies['age_0_5'] > 500])}")
        if len(age_anomalies[age_anomalies['age_0_5'] > 500]) > 0:
            anomaly_data = age_anomalies[age_anomalies['age_0_5'] > 500].nlargest(5, 'age_0_5')[
                ['date', 'state', 'district', 'age_0_5', 'age_5_17', 'age_18_greater']
            ]
            st.dataframe(anomaly_data, use_container_width=True)
    
    with col2:
        st.write(f"**Records with unusual age_18_greater concentration (>500):** {len(age_anomalies[age_anomalies['age_18_greater'] > 500])}")
        if len(age_anomalies[age_anomalies['age_18_greater'] > 500]) > 0:
            anomaly_data2 = age_anomalies[age_anomalies['age_18_greater'] > 500].nlargest(5, 'age_18_greater')[
                ['date', 'state', 'district', 'age_0_5', 'age_5_17', 'age_18_greater']
            ]
            st.dataframe(anomaly_data2, use_container_width=True)

# ========================================================================================
# PAGE 5: DATA QUALITY
# ========================================================================================
elif page == "Data Quality":
    st.title("üîç Data Quality Assessment")
    st.markdown("_Understanding data reliability and coverage_")
    st.markdown("---")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        duplicate_rows = df_full.duplicated(subset=['date', 'state', 'district', 'pincode', 'age_0_5', 'age_5_17', 'age_18_greater']).sum()
        st.metric(
            "üîÑ Duplicate Records",
            f"{duplicate_rows:,}",
            f"{duplicate_rows/len(df_full)*100:.2f}% of data"
        )
    
    with col2:
        missing_values = df_full.isnull().sum().sum()
        st.metric(
            "‚ùì Missing Values",
            f"{missing_values}",
            "All fields complete ‚úì"
        )
    
    with col3:
        zero_records = len(df_full[df_full['total_enrolment'] == 0])
        st.metric(
            "‚ö†Ô∏è Zero Records",
            f"{zero_records}",
            "None detected ‚úì"
        )
    
    st.markdown("---")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üìÆ Pincode Coverage")
        pincode_stats = {
            'Total Records': len(df_full),
            'Unique Pincodes': df_full['pincode'].nunique(),
            'Avg Records/Pincode': f"{len(df_full)/df_full['pincode'].nunique():.2f}",
            'Min Records/Pincode': df_full.groupby('pincode').size().min(),
            'Max Records/Pincode': df_full.groupby('pincode').size().max()
        }
        for key, value in pincode_stats.items():
            st.write(f"‚Ä¢ **{key}**: {value}")
    
    with col2:
        st.subheader("üìä Data Distribution Quality")
        quality_metrics = {
            'States Covered': df_full['state'].nunique(),
            'Districts Covered': df_full['district'].nunique(),
            'Date Range': f"{(df_full['date'].max() - df_full['date'].min()).days} days",
            'Records per State (avg)': f"{len(df_full)/df_full['state'].nunique():.0f}",
            'Records per District (avg)': f"{len(df_full)/df_full['district'].nunique():.0f}"
        }
        for key, value in quality_metrics.items():
            st.write(f"‚Ä¢ **{key}**: {value}")
    
    st.markdown("---")
    
    # Data quality trend
    st.subheader("üìà Data Quality Trend Over Time")
    quality_by_month = df_full.groupby(df_full['date'].dt.to_period('M')).agg({
        'total_enrolment': 'count',
        'state': 'nunique',
        'district': 'nunique'
    }).reset_index()
    quality_by_month.columns = ['Month', 'Records', 'States', 'Districts']
    quality_by_month['Month'] = quality_by_month['Month'].astype(str)
    
    fig_quality = go.Figure()
    fig_quality.add_trace(go.Scatter(x=quality_by_month['Month'], y=quality_by_month['Records'], name='Records', mode='lines+markers'))
    fig_quality.add_trace(go.Scatter(x=quality_by_month['Month'], y=quality_by_month['States']*100, name='States (√ó100)', mode='lines+markers'))
    fig_quality.update_layout(title='Data Coverage by Month', template='plotly_white', hovermode='x unified')
    st.plotly_chart(fig_quality, use_container_width=True)
    
    st.info("""
    **Data Quality Summary:**
    ‚úì No missing values in critical fields
    ‚úì All dates within valid range (Mar-Dec 2025)
    ‚úì Consistent geographic coverage (55 states, 985 districts)
    ‚úì All enrollment counts non-negative
    ‚úì Pincode distribution comprehensive
    """)

# ========================================================================================
# PAGE 6: INFRASTRUCTURE ANALYSIS
# ========================================================================================
elif page == "Infrastructure Analysis":
    st.title("üèõÔ∏è Enrollment Infrastructure Analysis")
    st.markdown("_Identifying enrollment hubs and infrastructure concentration_")
    st.markdown("---")
    
    # Pincode hubs
    st.subheader("üìç Top Enrollment Hubs (by Pincode)")
    pincode_distribution = df_full.groupby(['state', 'district', 'pincode']).agg({
        'total_enrolment': ['sum', 'count']
    }).reset_index()
    pincode_distribution.columns = ['state', 'district', 'pincode', 'total_enrolment', 'record_count']
    
    top_pincodes = pincode_distribution.nlargest(15, 'total_enrolment')
    
    fig_hubs = px.bar(
        top_pincodes,
        x='total_enrolment',
        y=top_pincodes['state'] + ' - ' + top_pincodes['district'] + ' (' + top_pincodes['pincode'].astype(str) + ')',
        orientation='h',
        title='Top 15 Enrollment Hubs',
        labels={'x': 'Total Enrolments'},
        template='plotly_white',
        color='total_enrolment',
        color_continuous_scale='Reds'
    )
    st.plotly_chart(fig_hubs, use_container_width=True)
    
    st.dataframe(top_pincodes, use_container_width=True)
    
    st.markdown("---")
    
    # Infrastructure concentration
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üèóÔ∏è Infrastructure Concentration")
        total_enrolments = pincode_distribution['total_enrolment'].sum()
        top_15_enrolments = top_pincodes['total_enrolment'].sum()
        concentration_pct = (top_15_enrolments / total_enrolments * 100)
        
        st.metric(
            "Top 15 Pincodes",
            f"{concentration_pct:.1f}%",
            "Of all enrollments"
        )
        
        st.write(f"""
        **Infrastructure Imbalance:**
        ‚Ä¢ Top 15 pincodes: {concentration_pct:.1f}% of enrollments
        ‚Ä¢ Remaining {len(pincode_distribution)-15} pincodes: {100-concentration_pct:.1f}%
        ‚Ä¢ Clear bottleneck identified
        """)
    
    with col2:
        st.subheader("üî¢ Pincode Activity Distribution")
        activity_levels = pincode_distribution['total_enrolment'].describe()
        
        st.write(f"""
        **Activity Statistics:**
        ‚Ä¢ Mean: {activity_levels['mean']:.0f}
        ‚Ä¢ Median: {activity_levels['50%']:.0f}
        ‚Ä¢ Std Dev: {activity_levels['std']:.0f}
        ‚Ä¢ Min: {activity_levels['min']:.0f}
        ‚Ä¢ Max: {activity_levels['max']:.0f}
        """)
    
    st.markdown("---")
    
    # State-level infrastructure
    st.subheader("‚öôÔ∏è Enrollment Efficiency by State")
    state_efficiency = df_full.groupby('state').agg({
        'total_enrolment': 'sum',
        'district': 'nunique',
        'pincode': 'nunique'
    }).round(0)
    state_efficiency.columns = ['Total_Enrolment', 'Districts', 'Pincodes']
    state_efficiency['Enrolment_per_District'] = (state_efficiency['Total_Enrolment'] / state_efficiency['Districts']).round(0)
    state_efficiency['Enrolment_per_Pincode'] = (state_efficiency['Total_Enrolment'] / state_efficiency['Pincodes']).round(0)
    state_efficiency = state_efficiency.sort_values('Total_Enrolment', ascending=False).head(15)
    
    st.dataframe(state_efficiency, use_container_width=True)

# ========================================================================================
# PAGE 7: KEY INSIGHTS
# ========================================================================================
elif page == "Key Insights":
    st.title("üí° Key Insights & Recommendations")
    st.markdown("---")
    
    # Calculate key metrics
    state_totals = df_full.groupby('state')['total_enrolment'].sum().sort_values(ascending=False)
    cumsum = state_totals.cumsum()
    cumsum_pct = (cumsum / cumsum.iloc[-1] * 100)
    states_80pct = (cumsum_pct[cumsum_pct <= 80].shape[0])
    total_states = state_totals.shape[0]
    
    daily_enrolments = df_full.groupby('date')['total_enrolment'].sum()
    dow_analysis = df_full.groupby('day_of_week')['total_enrolment'].sum().reindex(
        ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
    )
    weekday_avg = dow_analysis[['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']].mean()
    weekend_avg = (dow_analysis['Saturday'] + dow_analysis['Sunday']) / 2
    weekday_uplift = ((weekday_avg / weekend_avg - 1) * 100)
    
    # Display insights
    insight1, insight2 = st.columns([1, 1])
    
    with insight1:
        st.success(f"""
        ### 1Ô∏è‚É£ POLICY-DRIVEN ENROLLMENT
        **Weekday enrollment is {weekday_uplift:.1f}% higher than weekends**
        
        ‚Ä¢ Clear temporal pattern linked to government operations
        ‚Ä¢ Multiple spike days detected (major policy-driven campaigns)
        ‚Ä¢ Not organic user behavior - government-coordinated
        ‚Ä¢ **Action**: Focus campaigns on weekdays for maximum impact
        """)
    
    with insight2:
        st.warning(f"""
        ### 2Ô∏è‚É£ SEVERE GEOGRAPHIC CONCENTRATION
        **Just {states_80pct} states ({states_80pct/total_states*100:.1f}%) produce 80% of enrolments**
        
        ‚Ä¢ Clear Pareto distribution
        ‚Ä¢ Top 10% of districts = 40.5% of enrolments
        ‚Ä¢ Bottom 50% of districts = only 9.1%
        ‚Ä¢ **Action**: Expand infrastructure to underserved districts
        """)
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        age_0_5_pct = (df_full['age_0_5'].sum() / df_full['total_enrolment'].sum() * 100)
        age_5_17_pct = (df_full['age_5_17'].sum() / df_full['total_enrolment'].sum() * 100)
        age_18_pct = (df_full['age_18_greater'].sum() / df_full['total_enrolment'].sum() * 100)
        
        st.info(f"""
        ### 3Ô∏è‚É£ AGE-DRIVEN TARGETING
        **Enrollment reflects administrative priorities, not demographics**
        
        ‚Ä¢ 0-5 years: {age_0_5_pct:.1f}% - Child enrolment drives active
        ‚Ä¢ 5-17 years: {age_5_17_pct:.1f}% - School-based enrollment
        ‚Ä¢ 18+ years: {age_18_pct:.1f}% - Documents/ID needs
        ‚Ä¢ **Action**: Adjust messaging by age group and region
        """)
    
    with col2:
        st.error(f"""
        ### 4Ô∏è‚É£ INFRASTRUCTURE BOTTLENECK
        **Few pincodes handle majority of enrollments**
        
        ‚Ä¢ Top 15 pincodes = major enrollment hubs
        ‚Ä¢ Long tail of pincodes with minimal activity
        ‚Ä¢ Centralized infrastructure, not decentralized
        ‚Ä¢ **Action**: Identify geographic gaps and open new centers
        """)
    
    st.markdown("---")
    
    st.subheader("üéØ Strategic Recommendations")
    
    rec1, rec2 = st.columns([1, 1])
    
    with rec1:
        st.success(f"""
        ‚úÖ **HIGH IMPACT ACTIONS:**
        
        1. **Resource Allocation**
           - Focus on {states_80pct} high-activity states first
           - Covers 80% of national enrolment needs
           - Reduces implementation complexity
        
        2. **Weekend Expansion**
           - Current capacity underutilized by 33%
           - Weekend staffing expansion = easy gains
           - No policy change required
        
        3. **Urban-to-Rural Strategy**
           - Start from high-activity districts
           - Build infrastructure patterns from there
           - Track diffusion over time
        """)
    
    with col2:
        st.info("""
        üìä **DATA-DRIVEN INSIGHTS:**
        
        1. **Geographic Insights**
           - 985 districts across 55 states
           - Clear urban center dominance
           - Rural areas significantly underserved
        
        2. **Age Segmentation**
           - Child programs dominating
           - Youth enrollment strong
           - Adult enrollment minimal
           - Opportunity for adult-targeted campaigns
        
        3. **Operational Insights**
           - Batch processing evident in data
           - High-volume pincodes = efficient hubs
           - Infrastructure investment opportunity
        """)
    
    st.markdown("---")
    
    st.subheader("üìà Expected Outcomes")
    
    outcome_col1, outcome_col2, outcome_col3 = st.columns(3)
    
    with outcome_col1:
        st.metric("üéØ Focus on Top States", f"{states_80pct} states", "80% coverage achieved")
    
    with outcome_col2:
        st.metric("‚è∞ Weekend Capacity", "33% uplift", "Additional capacity")
    
    with outcome_col3:
        st.metric("üåç Geographic Spread", "985 districts", "Target for expansion")

# Footer
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: gray;'>
    <small>Aadhaar Enrolment Analysis Dashboard | Data Period: Mar-Dec 2025 | Last Updated: 2026</small>
</div>
""", unsafe_allow_html=True)
